# Optimized-Multimodal-LLM-Inference-Edge-Deployment

Github Resources:

1. llama file :
   https://github.com/Mozilla-Ocho/llamafile?tab=readme-ov-file
   
2. llama.cpp :
   https://github.com/ggml-org/llama.cpp?tab=readme-ov-file#obtaining-and-quantizing-models

Resource for models: 

 1. Image to text :
    https://huggingface.co/models?pipeline_tag=image-to-text&library=gguf&apps=llama.cpp&sort=trending

 3. Image-text to text :
    https://huggingface.co/models?pipeline_tag=image-text-to-text&library=gguf,transformers&apps=llama.cpp&sort=trending

List of all Image-text to text models : 
https://docs.google.com/spreadsheets/d/1wpVvum26Gi9Tb38AELnKxG8hJB__sT1VxkKhux-iT3g/edit?gid=181055174#gid=181055174

List of Quantized INT8 models : 
https://docs.google.com/spreadsheets/d/1wpVvum26Gi9Tb38AELnKxG8hJB__sT1VxkKhux-iT3g/edit?gid=1622818034#gid=1622818034

List of Quantized INT4 models : 
https://docs.google.com/spreadsheets/d/1wpVvum26Gi9Tb38AELnKxG8hJB__sT1VxkKhux-iT3g/edit?gid=0#gid=0
